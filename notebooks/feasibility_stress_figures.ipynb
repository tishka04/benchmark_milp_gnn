{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Feasibility & Stress Analysis Figures\n",
        "\n",
        "Ce notebook produit 5 figures clés pour l'analyse de la tenabilité physique des scénarios :\n",
        "\n",
        "1. **Figure 1** — Feasibility & Stress Map (heatmap)\n",
        "2. **Figure 2** — System Rigidity Gradient (stacked area)\n",
        "3. **Figure 3** — Localization of Flexibility Stress (carte zonale)\n",
        "4. **Figure 4** — Cost vs Feasibility Frontier (scatter)\n",
        "5. **Figure 5** — Feasibility-Preserving Scenario Exploration Pipeline (schéma méthodo)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "import json\n",
        "import pickle\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.colors import ListedColormap, BoundaryNorm\n",
        "from matplotlib.lines import Line2D\n",
        "import seaborn as sns\n",
        "from pathlib import Path\n",
        "from scipy.interpolate import griddata\n",
        "from collections import defaultdict\n",
        "\n",
        "# Setup paths\n",
        "BENCHMARK_ROOT = Path(r'C:\\Users\\Dell\\projects\\multilayer_milp_gnn\\benchmark')\n",
        "sys.path.insert(0, str(BENCHMARK_ROOT))\n",
        "\n",
        "# Paths to data\n",
        "PIPELINE_RESULTS_PATH = BENCHMARK_ROOT / 'outputs' / 'pipeline_eval' / 'pipeline_eval_results.pkl'\n",
        "MILP_REPORTS_DIR = BENCHMARK_ROOT / 'outputs' / 'scenarios_v1' / 'eval' / 'reports'\n",
        "SCENARIOS_DIR = BENCHMARK_ROOT / 'outputs' / 'scenarios_v1' / 'eval'\n",
        "\n",
        "# Output directory for figures\n",
        "FIG_OUTPUT_DIR = BENCHMARK_ROOT / 'outputs' / 'pipeline_eval' / 'feasibility_figures'\n",
        "FIG_OUTPUT_DIR.mkdir(exist_ok=True, parents=True)\n",
        "\n",
        "# Style settings\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.dpi'] = 150\n",
        "plt.rcParams['font.size'] = 11\n",
        "plt.rcParams['axes.titlesize'] = 14\n",
        "plt.rcParams['axes.labelsize'] = 12\n",
        "\n",
        "print(f\"Pipeline results: {PIPELINE_RESULTS_PATH.exists()}\")\n",
        "print(f\"MILP reports dir: {MILP_REPORTS_DIR.exists()}\")\n",
        "print(f\"Scenarios dir: {SCENARIOS_DIR.exists()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load pipeline results\n",
        "with open(PIPELINE_RESULTS_PATH, 'rb') as f:\n",
        "    pipeline_results = pickle.load(f)\n",
        "\n",
        "print(f\"Loaded {len(pipeline_results)} pipeline results\")\n",
        "\n",
        "# Build pipeline dataframe\n",
        "pipeline_data = []\n",
        "for item in pipeline_results:\n",
        "    sc_id = item['scenario_id']\n",
        "    lp_results = item.get('lp_results', [])\n",
        "    best_idx = item.get('best_sample_idx', 0)\n",
        "    \n",
        "    if lp_results and best_idx >= 0 and best_idx < len(lp_results):\n",
        "        lp_res = lp_results[best_idx]\n",
        "        \n",
        "        if hasattr(lp_res, 'scenario_id'):\n",
        "            row = {\n",
        "                'scenario_id': sc_id,\n",
        "                'status': lp_res.status,\n",
        "                'stage_used': lp_res.stage_used.value if hasattr(lp_res.stage_used, 'value') else str(lp_res.stage_used),\n",
        "                'objective_value': lp_res.objective_value,\n",
        "                'solve_time': lp_res.solve_time,\n",
        "                'slack_used': getattr(lp_res, 'slack_used', 0.0),\n",
        "                'n_flips': getattr(lp_res, 'n_flips', 0),\n",
        "                'slack_hard_fix': getattr(lp_res, 'slack_hard_fix', 0.0),\n",
        "                'slack_repair_20': getattr(lp_res, 'slack_repair_20', 0.0),\n",
        "                'slack_repair_100': getattr(lp_res, 'slack_repair_100', 0.0),\n",
        "                'slack_full_soft': getattr(lp_res, 'slack_full_soft', 0.0),\n",
        "            }\n",
        "        else:\n",
        "            row = {\n",
        "                'scenario_id': sc_id,\n",
        "                'status': lp_res.get('status', 'unknown'),\n",
        "                'stage_used': lp_res.get('stage_used', 'unknown'),\n",
        "                'objective_value': lp_res.get('objective_value', np.nan),\n",
        "                'solve_time': lp_res.get('solve_time', 0.0),\n",
        "                'slack_used': lp_res.get('slack_used', 0.0),\n",
        "                'n_flips': lp_res.get('n_flips', 0),\n",
        "                'slack_hard_fix': lp_res.get('slack_hard_fix', 0.0),\n",
        "                'slack_repair_20': lp_res.get('slack_repair_20', 0.0),\n",
        "                'slack_repair_100': lp_res.get('slack_repair_100', 0.0),\n",
        "                'slack_full_soft': lp_res.get('slack_full_soft', 0.0),\n",
        "            }\n",
        "        pipeline_data.append(row)\n",
        "\n",
        "df_pipeline = pd.DataFrame(pipeline_data)\n",
        "print(f\"Pipeline DataFrame: {df_pipeline.shape}\")\n",
        "print(f\"Stage distribution:\\n{df_pipeline['stage_used'].value_counts()}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load scenario metadata (for stress/structure dimensions)\n",
        "scenario_meta = {}\n",
        "for sc_file in SCENARIOS_DIR.glob('scenario_*.json'):\n",
        "    sc_id = sc_file.stem\n",
        "    with open(sc_file, 'r') as f:\n",
        "        data = json.load(f)\n",
        "    \n",
        "    # Extract key dimensions\n",
        "    meta = data.get('meta', {})\n",
        "    econ = data.get('econ_policy', {})\n",
        "    tech = data.get('tech', {})\n",
        "    exo = data.get('exogenous', {})\n",
        "    diff = data.get('difficulty_indicators', {})\n",
        "    flex = data.get('flexibility_metrics', {})\n",
        "    \n",
        "    scenario_meta[sc_id] = {\n",
        "        # Climate/Policy stress dimensions (X-axis candidates)\n",
        "        'co2_price': econ.get('co2_price', 100),\n",
        "        'demand_scale_factor': exo.get('demand_scale_factor', 1.0),\n",
        "        'inflow_factor': exo.get('inflow_factor', 1.0),\n",
        "        'weather_profile': exo.get('weather_profile', 'mixed'),\n",
        "        'weather_spread_intensity': exo.get('weather_spread_intensity', 1.0),\n",
        "        'cross_border_policy': econ.get('cross_border_policy', 'allow'),\n",
        "        \n",
        "        # Structural dimensions (Y-axis candidates)\n",
        "        'vre_penetration_pct': diff.get('vre_penetration_pct', 30),\n",
        "        'total_storage_power_mw': flex.get('total_storage_power_mw', 0),\n",
        "        'total_storage_capacity_mwh': flex.get('total_storage_capacity_mwh', 0),\n",
        "        'total_dr_capacity_mw': flex.get('total_dr_capacity_mw', 0),\n",
        "        'battery_roundtrip_efficiency': tech.get('battery_roundtrip_eff', 0.9),\n",
        "        'dr_max_shed_share': tech.get('dr_max_shed_share', 0.1),\n",
        "        'thermal_ramp_pct': tech.get('thermal_ramp_pct', 0.5),\n",
        "        \n",
        "        # Other useful metrics\n",
        "        'n_zones': meta.get('zones', 50),\n",
        "        'n_regions': meta.get('regions', 5),\n",
        "        'complexity_score': diff.get('complexity_score', 'medium'),\n",
        "        'peak_to_valley_ratio': diff.get('peak_to_valley_ratio', 1.5),\n",
        "        'net_demand_volatility': diff.get('net_demand_volatility', 0.2),\n",
        "    }\n",
        "\n",
        "print(f\"Loaded metadata for {len(scenario_meta)} scenarios\")\n",
        "\n",
        "# Merge with pipeline data\n",
        "meta_df = pd.DataFrame.from_dict(scenario_meta, orient='index')\n",
        "meta_df.index.name = 'scenario_id'\n",
        "meta_df = meta_df.reset_index()\n",
        "\n",
        "df = df_pipeline.merge(meta_df, on='scenario_id', how='inner')\n",
        "print(f\"Merged DataFrame: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load MILP reports for cost comparison\n",
        "milp_reports = {}\n",
        "for report_file in MILP_REPORTS_DIR.glob('scenario_*.json'):\n",
        "    sc_id = report_file.stem\n",
        "    with open(report_file, 'r') as f:\n",
        "        milp_reports[sc_id] = json.load(f)\n",
        "\n",
        "# Add MILP objective to df\n",
        "df['milp_objective'] = df['scenario_id'].apply(\n",
        "    lambda x: milp_reports.get(x, {}).get('mip', {}).get('objective', np.nan)\n",
        ")\n",
        "print(f\"Added MILP objectives: {df['milp_objective'].notna().sum()} scenarios\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Figure 1 — Feasibility & Stress Map of Power System Futures\n",
        "\n",
        "**Carte de tenabilité physique** montrant comment la faisabilité varie selon :\n",
        "- **Axe X** : Prix CO₂ (stress politique/économique)\n",
        "- **Axe Y** : Pénétration VRE (structure du mix)\n",
        "- **Couleur** : SolveStage dominant (vert=hard_fix, jaune=repair, rouge=full_soft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIGURE 1: Feasibility & Stress Map\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "# Define stage colors and numeric mapping\n",
        "stage_colors = {'hard_fix': '#2ecc71', 'repair_20': '#f1c40f', 'repair_100': '#e67e22', 'full_soft': '#e74c3c'}\n",
        "stage_numeric = {'hard_fix': 2, 'repair_20': 1.5, 'repair_100': 1, 'full_soft': 0}\n",
        "\n",
        "# Map stages to numeric values\n",
        "df['stage_numeric'] = df['stage_used'].map(stage_numeric)\n",
        "\n",
        "# ===== Panel A: CO2 Price vs VRE Penetration =====\n",
        "ax1 = axes[0]\n",
        "\n",
        "# Create scatter with stage colors\n",
        "for stage, color in stage_colors.items():\n",
        "    mask = df['stage_used'] == stage\n",
        "    if mask.sum() > 0:\n",
        "        ax1.scatter(df.loc[mask, 'co2_price'], df.loc[mask, 'vre_penetration_pct'],\n",
        "                   c=color, label=stage, s=120, alpha=0.8, edgecolors='white', linewidth=1)\n",
        "\n",
        "ax1.set_xlabel('CO₂ Price (EUR/t)', fontsize=12)\n",
        "ax1.set_ylabel('VRE Penetration (%)', fontsize=12)\n",
        "ax1.set_title('(A) Stress Map: CO₂ Price vs VRE Penetration', fontsize=14, fontweight='bold')\n",
        "ax1.legend(title='SolveStage', loc='upper right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# ===== Panel B: Demand Scale vs Storage Capacity =====\n",
        "ax2 = axes[1]\n",
        "\n",
        "# Normalize storage for better visualization\n",
        "df['storage_gw'] = df['total_storage_power_mw'] / 1000\n",
        "\n",
        "for stage, color in stage_colors.items():\n",
        "    mask = df['stage_used'] == stage\n",
        "    if mask.sum() > 0:\n",
        "        ax2.scatter(df.loc[mask, 'demand_scale_factor'], df.loc[mask, 'storage_gw'],\n",
        "                   c=color, label=stage, s=120, alpha=0.8, edgecolors='white', linewidth=1)\n",
        "\n",
        "ax2.set_xlabel('Demand Scale Factor', fontsize=12)\n",
        "ax2.set_ylabel('Total Storage Power (GW)', fontsize=12)\n",
        "ax2.set_title('(B) Stress Map: Demand Stress vs Storage Capacity', fontsize=14, fontweight='bold')\n",
        "ax2.legend(title='SolveStage', loc='upper right')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig1_feasibility_stress_map.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig1_feasibility_stress_map.pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIGURE 1 SUMMARY: Feasibility & Stress Map\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Scenarios by SolveStage:\")\n",
        "for stage in ['hard_fix', 'repair_20', 'repair_100', 'full_soft']:\n",
        "    n = (df['stage_used'] == stage).sum()\n",
        "    pct = n / len(df) * 100\n",
        "    print(f\"  {stage}: {n} ({pct:.1f}%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Figure 2 — System Rigidity Gradient under Climate and Policy Stress\n",
        "\n",
        "**Stacked area plot** montrant la distribution des SolveStages en fonction d'un paramètre de stress croissant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIGURE 2: System Rigidity Gradient\n",
        "fig, axes = plt.subplots(1, 2, figsize=(16, 5))\n",
        "\n",
        "# ===== Panel A: Rigidity vs VRE Penetration =====\n",
        "ax1 = axes[0]\n",
        "\n",
        "# Create bins for VRE penetration\n",
        "n_bins = 6\n",
        "df['vre_bin'] = pd.cut(df['vre_penetration_pct'], bins=n_bins, labels=False)\n",
        "vre_edges = pd.cut(df['vre_penetration_pct'], bins=n_bins).cat.categories\n",
        "\n",
        "# Compute stage distribution per bin\n",
        "stages = ['hard_fix', 'repair_20', 'repair_100', 'full_soft']\n",
        "stage_colors_list = ['#2ecc71', '#f1c40f', '#e67e22', '#e74c3c']\n",
        "\n",
        "bin_data = []\n",
        "bin_labels = []\n",
        "for i, interval in enumerate(vre_edges):\n",
        "    bin_mask = df['vre_bin'] == i\n",
        "    bin_total = bin_mask.sum()\n",
        "    if bin_total > 0:\n",
        "        bin_labels.append(f\"{interval.left:.0f}-{interval.right:.0f}\")\n",
        "        row = {}\n",
        "        for stage in stages:\n",
        "            stage_count = ((df['stage_used'] == stage) & bin_mask).sum()\n",
        "            row[stage] = stage_count / bin_total * 100\n",
        "        bin_data.append(row)\n",
        "\n",
        "bin_df = pd.DataFrame(bin_data)\n",
        "x = np.arange(len(bin_labels))\n",
        "\n",
        "# Stacked bar chart\n",
        "bottom = np.zeros(len(bin_labels))\n",
        "for stage, color in zip(stages, stage_colors_list):\n",
        "    if stage in bin_df.columns:\n",
        "        values = bin_df[stage].values\n",
        "        ax1.bar(x, values, bottom=bottom, label=stage, color=color, alpha=0.85, width=0.7)\n",
        "        bottom += values\n",
        "\n",
        "ax1.set_xticks(x)\n",
        "ax1.set_xticklabels(bin_labels, rotation=30)\n",
        "ax1.set_xlabel('VRE Penetration (%)', fontsize=12)\n",
        "ax1.set_ylabel('Proportion (%)', fontsize=12)\n",
        "ax1.set_title('(A) System Rigidity vs VRE Penetration', fontsize=14, fontweight='bold')\n",
        "ax1.legend(loc='upper left', title='SolveStage')\n",
        "ax1.set_ylim(0, 105)\n",
        "ax1.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# ===== Panel B: Rigidity vs Demand Stress =====\n",
        "ax2 = axes[1]\n",
        "\n",
        "# Create bins for demand scale\n",
        "df['demand_bin'] = pd.cut(df['demand_scale_factor'], bins=n_bins, labels=False)\n",
        "demand_edges = pd.cut(df['demand_scale_factor'], bins=n_bins).cat.categories\n",
        "\n",
        "bin_data2 = []\n",
        "bin_labels2 = []\n",
        "for i, interval in enumerate(demand_edges):\n",
        "    bin_mask = df['demand_bin'] == i\n",
        "    bin_total = bin_mask.sum()\n",
        "    if bin_total > 0:\n",
        "        bin_labels2.append(f\"{interval.left:.2f}-{interval.right:.2f}\")\n",
        "        row = {}\n",
        "        for stage in stages:\n",
        "            stage_count = ((df['stage_used'] == stage) & bin_mask).sum()\n",
        "            row[stage] = stage_count / bin_total * 100\n",
        "        bin_data2.append(row)\n",
        "\n",
        "bin_df2 = pd.DataFrame(bin_data2)\n",
        "x2 = np.arange(len(bin_labels2))\n",
        "\n",
        "bottom2 = np.zeros(len(bin_labels2))\n",
        "for stage, color in zip(stages, stage_colors_list):\n",
        "    if stage in bin_df2.columns:\n",
        "        values = bin_df2[stage].values\n",
        "        ax2.bar(x2, values, bottom=bottom2, label=stage, color=color, alpha=0.85, width=0.7)\n",
        "        bottom2 += values\n",
        "\n",
        "ax2.set_xticks(x2)\n",
        "ax2.set_xticklabels(bin_labels2, rotation=30)\n",
        "ax2.set_xlabel('Demand Scale Factor', fontsize=12)\n",
        "ax2.set_ylabel('Proportion (%)', fontsize=12)\n",
        "ax2.set_title('(B) System Rigidity vs Demand Stress', fontsize=14, fontweight='bold')\n",
        "ax2.legend(loc='upper left', title='SolveStage')\n",
        "ax2.set_ylim(0, 105)\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig2_rigidity_gradient.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig2_rigidity_gradient.pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIGURE 2 SUMMARY: System Rigidity Gradient\")\n",
        "print(f\"{'='*60}\")\n",
        "print(\"Interpretation:\")\n",
        "print(\"  - More green (hard_fix) = system is physically tenable\")\n",
        "print(\"  - More yellow/orange (repair) = corrective interventions needed\")\n",
        "print(\"  - More red (full_soft) = significant slack required for feasibility\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Figure 3 — Localization of Flexibility Stress\n",
        "\n",
        "**Carte zonale** montrant quels types d'assets ou zones déclenchent le plus de corrections (repairs, slacks, flips)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIGURE 3: Localization of Flexibility Stress\n",
        "# We'll analyze which scenario characteristics correlate with repair/slack interventions\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
        "\n",
        "# ===== Panel A: Slack usage by weather profile =====\n",
        "ax1 = axes[0, 0]\n",
        "\n",
        "weather_slack = df.groupby('weather_profile').agg({\n",
        "    'slack_used': 'mean',\n",
        "    'n_flips': 'mean',\n",
        "    'scenario_id': 'count'\n",
        "}).rename(columns={'scenario_id': 'count'})\n",
        "weather_slack = weather_slack.sort_values('slack_used', ascending=True)\n",
        "\n",
        "colors_weather = plt.cm.YlOrRd(np.linspace(0.2, 0.9, len(weather_slack)))\n",
        "bars = ax1.barh(weather_slack.index, weather_slack['slack_used'], color=colors_weather, alpha=0.85)\n",
        "ax1.set_xlabel('Mean Slack Used (MWh)', fontsize=12)\n",
        "ax1.set_ylabel('Weather Profile', fontsize=12)\n",
        "ax1.set_title('(A) Flexibility Stress by Weather Profile', fontsize=13, fontweight='bold')\n",
        "\n",
        "# Add count annotations\n",
        "for bar, count in zip(bars, weather_slack['count']):\n",
        "    ax1.text(bar.get_width() + 10, bar.get_y() + bar.get_height()/2, \n",
        "             f'n={int(count)}', va='center', fontsize=9)\n",
        "\n",
        "ax1.grid(True, alpha=0.3, axis='x')\n",
        "\n",
        "# ===== Panel B: Repair frequency by complexity =====\n",
        "ax2 = axes[0, 1]\n",
        "\n",
        "# Define repair stages\n",
        "df['needs_repair'] = df['stage_used'].isin(['repair_20', 'repair_100', 'full_soft'])\n",
        "df['needs_full_soft'] = df['stage_used'] == 'full_soft'\n",
        "\n",
        "complexity_repair = df.groupby('complexity_score').agg({\n",
        "    'needs_repair': 'mean',\n",
        "    'needs_full_soft': 'mean',\n",
        "    'scenario_id': 'count'\n",
        "}).rename(columns={'scenario_id': 'count'})\n",
        "\n",
        "x_pos = np.arange(len(complexity_repair))\n",
        "width = 0.35\n",
        "\n",
        "bars1 = ax2.bar(x_pos - width/2, complexity_repair['needs_repair'] * 100, width, \n",
        "               label='Any Repair', color='#f39c12', alpha=0.85)\n",
        "bars2 = ax2.bar(x_pos + width/2, complexity_repair['needs_full_soft'] * 100, width,\n",
        "               label='Full Soft', color='#e74c3c', alpha=0.85)\n",
        "\n",
        "ax2.set_xticks(x_pos)\n",
        "ax2.set_xticklabels(complexity_repair.index)\n",
        "ax2.set_xlabel('Complexity Score', fontsize=12)\n",
        "ax2.set_ylabel('Frequency (%)', fontsize=12)\n",
        "ax2.set_title('(B) Repair Frequency by Scenario Complexity', fontsize=13, fontweight='bold')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# ===== Panel C: Number of flips vs peak-to-valley ratio =====\n",
        "ax3 = axes[1, 0]\n",
        "\n",
        "scatter_colors = [stage_colors.get(s, 'gray') for s in df['stage_used']]\n",
        "ax3.scatter(df['peak_to_valley_ratio'], df['n_flips'], c=scatter_colors, \n",
        "           s=80, alpha=0.7, edgecolors='white', linewidth=0.5)\n",
        "\n",
        "ax3.set_xlabel('Peak-to-Valley Ratio', fontsize=12)\n",
        "ax3.set_ylabel('Number of Binary Flips', fontsize=12)\n",
        "ax3.set_title('(C) Corrective Flips vs Demand Variability', fontsize=13, fontweight='bold')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Add legend\n",
        "legend_elements = [mpatches.Patch(facecolor=c, label=s, alpha=0.85) \n",
        "                   for s, c in stage_colors.items()]\n",
        "ax3.legend(handles=legend_elements, title='SolveStage', loc='upper right')\n",
        "\n",
        "# ===== Panel D: Slack intensity heatmap by VRE and demand =====\n",
        "ax4 = axes[1, 1]\n",
        "\n",
        "# Create 2D bins\n",
        "vre_bins = pd.cut(df['vre_penetration_pct'], bins=5, labels=[f'{i+1}' for i in range(5)])\n",
        "demand_bins = pd.cut(df['demand_scale_factor'], bins=5, labels=[f'{i+1}' for i in range(5)])\n",
        "\n",
        "df['vre_bin_label'] = vre_bins\n",
        "df['demand_bin_label'] = demand_bins\n",
        "\n",
        "pivot_data = df.pivot_table(values='slack_used', index='demand_bin_label', \n",
        "                            columns='vre_bin_label', aggfunc='mean')\n",
        "\n",
        "sns.heatmap(pivot_data, ax=ax4, cmap='YlOrRd', annot=True, fmt='.0f',\n",
        "           cbar_kws={'label': 'Mean Slack (MWh)'})\n",
        "ax4.set_xlabel('VRE Penetration Bin (low → high)', fontsize=12)\n",
        "ax4.set_ylabel('Demand Stress Bin (low → high)', fontsize=12)\n",
        "ax4.set_title('(D) Slack Intensity by VRE × Demand', fontsize=13, fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig3_flexibility_stress_localization.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig3_flexibility_stress_localization.pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIGURE 3 SUMMARY: Localization of Flexibility Stress\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"Mean slack by weather:\")\n",
        "for wp, row in weather_slack.iterrows():\n",
        "    print(f\"  {wp}: {row['slack_used']:.1f} MWh (n={int(row['count'])})\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Figure 4 — Cost vs Feasibility Frontier\n",
        "\n",
        "**Scatter plot** montrant le compromis entre coût et niveau de faisabilité."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIGURE 4: Cost vs Feasibility Frontier\n",
        "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "# ===== Panel A: Pipeline Cost vs Feasibility Index =====\n",
        "ax1 = axes[0]\n",
        "\n",
        "# Map stage_used to feasibility index (0=full_soft, 1=repair, 2=hard_fix)\n",
        "feasibility_index = {\n",
        "    'hard_fix': 2.0,\n",
        "    'repair_20': 1.5,\n",
        "    'repair_100': 1.0,\n",
        "    'full_soft': 0.0\n",
        "}\n",
        "df['feasibility_index'] = df['stage_used'].map(feasibility_index)\n",
        "\n",
        "# Add jitter to feasibility for better visualization\n",
        "jitter = np.random.uniform(-0.1, 0.1, len(df))\n",
        "df['feasibility_jitter'] = df['feasibility_index'] + jitter\n",
        "\n",
        "# Scatter plot\n",
        "for stage, color in stage_colors.items():\n",
        "    mask = df['stage_used'] == stage\n",
        "    if mask.sum() > 0:\n",
        "        ax1.scatter(df.loc[mask, 'objective_value'] / 1e6, \n",
        "                   df.loc[mask, 'feasibility_jitter'],\n",
        "                   c=color, label=stage, s=100, alpha=0.75, \n",
        "                   edgecolors='white', linewidth=1)\n",
        "\n",
        "ax1.set_xlabel('Pipeline Objective Cost (M EUR)', fontsize=12)\n",
        "ax1.set_ylabel('Feasibility Index', fontsize=12)\n",
        "ax1.set_yticks([0, 1, 1.5, 2])\n",
        "ax1.set_yticklabels(['full_soft\\n(0)', 'repair_100\\n(1)', 'repair_20\\n(1.5)', 'hard_fix\\n(2)'])\n",
        "ax1.set_title('(A) Cost vs Feasibility Frontier', fontsize=14, fontweight='bold')\n",
        "ax1.legend(title='SolveStage', loc='upper right')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Annotate ideal region\n",
        "ax1.axhspan(1.5, 2.1, alpha=0.1, color='green')\n",
        "ax1.text(df['objective_value'].min()/1e6 + 0.5, 1.8, 'Ideal: Low Cost, High Feasibility', \n",
        "        fontsize=10, color='darkgreen', style='italic')\n",
        "\n",
        "# ===== Panel B: Cost Gap vs Feasibility =====\n",
        "ax2 = axes[1]\n",
        "\n",
        "# Calculate cost gap vs MILP\n",
        "df['cost_gap_pct'] = (df['objective_value'] - df['milp_objective']) / df['milp_objective'] * 100\n",
        "\n",
        "for stage, color in stage_colors.items():\n",
        "    mask = df['stage_used'] == stage\n",
        "    if mask.sum() > 0:\n",
        "        ax2.scatter(df.loc[mask, 'cost_gap_pct'], \n",
        "                   df.loc[mask, 'feasibility_jitter'],\n",
        "                   c=color, label=stage, s=100, alpha=0.75,\n",
        "                   edgecolors='white', linewidth=1)\n",
        "\n",
        "ax2.axvline(x=0, color='gray', linestyle='--', alpha=0.5)\n",
        "ax2.set_xlabel('Cost Gap vs MILP (%)', fontsize=12)\n",
        "ax2.set_ylabel('Feasibility Index', fontsize=12)\n",
        "ax2.set_yticks([0, 1, 1.5, 2])\n",
        "ax2.set_yticklabels(['full_soft\\n(0)', 'repair_100\\n(1)', 'repair_20\\n(1.5)', 'hard_fix\\n(2)'])\n",
        "ax2.set_title('(B) Optimality Gap vs Feasibility Frontier', fontsize=14, fontweight='bold')\n",
        "ax2.legend(title='SolveStage', loc='upper right')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# Annotate trade-off zones\n",
        "ax2.axhspan(1.5, 2.1, alpha=0.1, color='green')\n",
        "ax2.axvspan(-10, 10, alpha=0.08, color='blue')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig4_cost_feasibility_frontier.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig4_cost_feasibility_frontier.pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIGURE 4 SUMMARY: Cost vs Feasibility Frontier\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"\\nFeasibility Index Interpretation:\")\n",
        "print(f\"  2 = hard_fix (decoder plan directly feasible)\")\n",
        "print(f\"  1.5 = repair_20 (minor corrections needed)\")\n",
        "print(f\"  1 = repair_100 (moderate corrections needed)\")\n",
        "print(f\"  0 = full_soft (slack variables required)\")\n",
        "print(f\"\\nMean cost gap by stage:\")\n",
        "for stage in ['hard_fix', 'repair_20', 'repair_100', 'full_soft']:\n",
        "    mask = df['stage_used'] == stage\n",
        "    if mask.sum() > 0:\n",
        "        mean_gap = df.loc[mask, 'cost_gap_pct'].mean()\n",
        "        print(f\"  {stage}: {mean_gap:+.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Figure 5 — Feasibility-Preserving Scenario Exploration Pipeline\n",
        "\n",
        "**Schéma méthodologique** illustrant le rôle des différents composants :\n",
        "- **MILP** = Oracle rare (validation)\n",
        "- **GNN–EBM** = Explorateur (génération de candidats)\n",
        "- **LP Worker** = Gardien de la physique (validation rapide)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# FIGURE 5: Pipeline Methodology Diagram\n",
        "fig, ax = plt.subplots(1, 1, figsize=(16, 10))\n",
        "ax.set_xlim(0, 16)\n",
        "ax.set_ylim(0, 10)\n",
        "ax.axis('off')\n",
        "\n",
        "# Title\n",
        "ax.text(8, 9.5, 'Feasibility-Preserving Scenario Exploration Pipeline', \n",
        "        fontsize=18, fontweight='bold', ha='center', va='center')\n",
        "\n",
        "# === Component boxes ===\n",
        "box_style = dict(boxstyle='round,pad=0.5', facecolor='white', edgecolor='black', linewidth=2)\n",
        "\n",
        "# 1. Scenario Space (top left)\n",
        "ax.add_patch(plt.Rectangle((0.5, 6.5), 3, 2, fill=True, facecolor='#E8F4FD', \n",
        "                           edgecolor='#2980b9', linewidth=2, zorder=1))\n",
        "ax.text(2, 7.8, 'Scenario Space', fontsize=12, fontweight='bold', ha='center')\n",
        "ax.text(2, 7.2, '• CO₂ price\\n• VRE penetration\\n• Demand profile', \n",
        "        fontsize=9, ha='center', va='top', linespacing=1.3)\n",
        "\n",
        "# 2. GNN Encoder (top center)\n",
        "ax.add_patch(plt.Rectangle((5, 6.5), 3, 2, fill=True, facecolor='#E8F8E8', \n",
        "                           edgecolor='#27ae60', linewidth=2, zorder=1))\n",
        "ax.text(6.5, 7.8, 'GNN Encoder', fontsize=12, fontweight='bold', ha='center')\n",
        "ax.text(6.5, 7.2, '• HGT layers\\n• Scenario embedding\\n• Structure learning', \n",
        "        fontsize=9, ha='center', va='top', linespacing=1.3)\n",
        "\n",
        "# 3. EBM Sampler (top right)\n",
        "ax.add_patch(plt.Rectangle((9.5, 6.5), 3, 2, fill=True, facecolor='#FFF8E8', \n",
        "                           edgecolor='#f39c12', linewidth=2, zorder=1))\n",
        "ax.text(11, 7.8, 'EBM Sampler', fontsize=12, fontweight='bold', ha='center')\n",
        "ax.text(11, 7.2, '• Langevin dynamics\\n• k=5 candidates\\n• Energy-guided', \n",
        "        fontsize=9, ha='center', va='top', linespacing=1.3)\n",
        "\n",
        "# 4. Decoder (center)\n",
        "ax.add_patch(plt.Rectangle((5, 4), 3, 2, fill=True, facecolor='#F8E8F8', \n",
        "                           edgecolor='#9b59b6', linewidth=2, zorder=1))\n",
        "ax.text(6.5, 5.3, 'Feasibility Decoder', fontsize=12, fontweight='bold', ha='center')\n",
        "ax.text(6.5, 4.7, '• Binary decisions\\n• Greedy feasibility\\n• Constraint-aware', \n",
        "        fontsize=9, ha='center', va='top', linespacing=1.3)\n",
        "\n",
        "# 5. LP Worker (center-right) - MAIN FOCUS\n",
        "ax.add_patch(plt.Rectangle((9.5, 4), 4, 2, fill=True, facecolor='#E8E8F8', \n",
        "                           edgecolor='#3498db', linewidth=3, zorder=1))\n",
        "ax.text(11.5, 5.4, 'LP Worker', fontsize=14, fontweight='bold', ha='center', color='#2c3e50')\n",
        "ax.text(11.5, 5.0, '\"Guardian of Physics\"', fontsize=10, ha='center', style='italic', color='#7f8c8d')\n",
        "ax.text(11.5, 4.5, '• Hard-fix → Repair → Full-soft\\n• Continuous optimization\\n• Slack tracking', \n",
        "        fontsize=9, ha='center', va='top', linespacing=1.3)\n",
        "\n",
        "# 6. MILP Oracle (bottom)\n",
        "ax.add_patch(plt.Rectangle((5, 1), 6, 2, fill=True, facecolor='#F8E8E8', \n",
        "                           edgecolor='#e74c3c', linewidth=2, linestyle='--', zorder=1))\n",
        "ax.text(8, 2.4, 'MILP Oracle', fontsize=14, fontweight='bold', ha='center', color='#c0392b')\n",
        "ax.text(8, 1.9, '\"Rare Validation\"', fontsize=10, ha='center', style='italic', color='#7f8c8d')\n",
        "ax.text(8, 1.5, '• Ground truth • 7000+ sec/scenario • Used for evaluation only', \n",
        "        fontsize=9, ha='center', va='top')\n",
        "\n",
        "# === Arrows ===\n",
        "arrow_style = dict(arrowstyle='->', color='#2c3e50', lw=2)\n",
        "\n",
        "# Scenario -> GNN\n",
        "ax.annotate('', xy=(5, 7.5), xytext=(3.5, 7.5), arrowprops=arrow_style)\n",
        "\n",
        "# GNN -> EBM\n",
        "ax.annotate('', xy=(9.5, 7.5), xytext=(8, 7.5), arrowprops=arrow_style)\n",
        "\n",
        "# EBM -> Decoder\n",
        "ax.annotate('', xy=(7.5, 6), xytext=(10.5, 6.5), arrowprops=dict(arrowstyle='->', \n",
        "            color='#2c3e50', lw=2, connectionstyle='arc3,rad=-0.3'))\n",
        "\n",
        "# Decoder -> LP Worker\n",
        "ax.annotate('', xy=(9.5, 5), xytext=(8, 5), arrowprops=arrow_style)\n",
        "\n",
        "# LP Worker outputs (feedback loop)\n",
        "ax.annotate('', xy=(13.5, 5), xytext=(13.5, 7.5), \n",
        "           arrowprops=dict(arrowstyle='->', color='#27ae60', lw=2, ls='--'))\n",
        "ax.text(14.2, 6.2, 'Best\\nSolution', fontsize=9, ha='left', color='#27ae60', fontweight='bold')\n",
        "\n",
        "# MILP connection (dotted - rare use)\n",
        "ax.annotate('', xy=(8, 4), xytext=(8, 3), \n",
        "           arrowprops=dict(arrowstyle='<->', color='#e74c3c', lw=1.5, ls=':'))\n",
        "ax.text(8.5, 3.5, 'Validation\\n(offline)', fontsize=8, ha='left', color='#e74c3c', style='italic')\n",
        "\n",
        "# === Stage indicators box ===\n",
        "ax.add_patch(plt.Rectangle((0.5, 1), 3.5, 2.5), fill=True, facecolor='#FAFAFA', \n",
        "             edgecolor='#bdc3c7', linewidth=1)\n",
        "ax.text(2.25, 3.2, 'SolveStage Legend', fontsize=10, fontweight='bold', ha='center')\n",
        "\n",
        "stages_legend = [\n",
        "    ('hard_fix', '#2ecc71', 'Direct feasibility'),\n",
        "    ('repair_20', '#f1c40f', 'Minor corrections'),\n",
        "    ('repair_100', '#e67e22', 'Moderate corrections'),\n",
        "    ('full_soft', '#e74c3c', 'Slack required'),\n",
        "]\n",
        "for i, (stage, color, desc) in enumerate(stages_legend):\n",
        "    y_pos = 2.7 - i * 0.4\n",
        "    ax.add_patch(plt.Rectangle((0.7, y_pos - 0.1), 0.3, 0.25, facecolor=color, edgecolor='black'))\n",
        "    ax.text(1.1, y_pos, f'{stage}: {desc}', fontsize=8, va='center')\n",
        "\n",
        "# === Performance stats box ===\n",
        "ax.add_patch(plt.Rectangle((13, 1), 2.8, 2.5), fill=True, facecolor='#FAFAFA', \n",
        "             edgecolor='#bdc3c7', linewidth=1)\n",
        "ax.text(14.4, 3.2, 'Performance', fontsize=10, fontweight='bold', ha='center')\n",
        "\n",
        "# Calculate stats from data\n",
        "hard_fix_pct = (df['stage_used'] == 'hard_fix').mean() * 100\n",
        "repair_pct = df['stage_used'].isin(['repair_20', 'repair_100']).mean() * 100\n",
        "full_soft_pct = (df['stage_used'] == 'full_soft').mean() * 100\n",
        "\n",
        "stats_text = f\"\"\"hard_fix: {hard_fix_pct:.0f}%\n",
        "repair: {repair_pct:.0f}%\n",
        "full_soft: {full_soft_pct:.0f}%\n",
        "Speedup: ~200x\"\"\"\n",
        "ax.text(14.4, 2.5, stats_text, fontsize=9, ha='center', va='top', linespacing=1.4,\n",
        "       family='monospace')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig5_pipeline_methodology.png', dpi=300, bbox_inches='tight')\n",
        "plt.savefig(FIG_OUTPUT_DIR / 'fig5_pipeline_methodology.pdf', bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\n{'='*60}\")\n",
        "print(\"FIGURE 5 SUMMARY: Pipeline Methodology\")\n",
        "print(f\"{'='*60}\")\n",
        "print(\"Key roles in the pipeline:\")\n",
        "print(\"  • MILP: Oracle rare - ground truth, but ~7000s/scenario\")\n",
        "print(\"  • GNN-EBM: Explorateur - generates diverse candidates\")\n",
        "print(\"  • LP Worker: Gardien de la physique - validates in ~50s\")\n",
        "print(f\"\\nCurrent distribution on {len(df)} scenarios:\")\n",
        "print(f\"  • Direct feasibility (hard_fix): {hard_fix_pct:.1f}%\")\n",
        "print(f\"  • Corrective repairs: {repair_pct:.1f}%\")\n",
        "print(f\"  • Full soft relaxation: {full_soft_pct:.1f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "## Summary: All Figures Exported\n",
        "\n",
        "Les figures ont été exportées dans le dossier `outputs/pipeline_eval/feasibility_figures/`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# List all exported figures\n",
        "print(\"=\"*60)\n",
        "print(\"EXPORTED FIGURES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for fig_file in sorted(FIG_OUTPUT_DIR.glob('fig*.png')):\n",
        "    size_kb = fig_file.stat().st_size / 1024\n",
        "    print(f\"  ✓ {fig_file.name} ({size_kb:.1f} KB)\")\n",
        "\n",
        "print(f\"\\nOutput directory: {FIG_OUTPUT_DIR}\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
