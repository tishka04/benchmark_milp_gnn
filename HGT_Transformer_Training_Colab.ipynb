{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "header"
      },
      "source": [
        "# HGT + Temporal Transformer Encoder Training on Google Colab\n",
        "\n",
        "This notebook trains the **HGT + Temporal Transformer Encoder** for Energy Balance Model (EBM) on an **A100 GPU**.\n",
        "\n",
        "## Architecture Overview\n",
        "\n",
        "1. **HGT (Heterogeneous Graph Transformer)**: Spatial encoding across heterogeneous nodes\n",
        "2. **Temporal Transformer**: Self-attention across time dimension\n",
        "3. **Encoder-only**: Outputs embeddings for EBM training (no decoder)\n",
        "\n",
        "## Setup Requirements\n",
        "\n",
        "- **GPU**: A100 (40GB or 80GB)\n",
        "- **Runtime**: Python 3.10+\n",
        "- **Google Drive**: Repository mounted at `/content/drive/MyDrive/benchmark`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mount-drive"
      },
      "source": [
        "## 1. Mount Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "mount-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "17955cb8-669e-4d47-a563-13b47951cd81"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Current directory: /content/drive/MyDrive/benchmark\n",
            "Repository contents:\n",
            "total 258\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  code_writings\n",
            "-rw------- 1 root root   3577 Nov 28 16:54  COLAB_QUICK_START.md\n",
            "-rw------- 1 root root   8471 Nov 28 16:52  COLAB_TRAINING_GUIDE.md\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  config\n",
            "-rw------- 1 root root 131628 Dec  1 14:29 'Copie de HGT_Transformer_Training_Colab.ipynb'\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  docs\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  experimental\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  extracted_pdfs\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  .git\n",
            "-rw------- 1 root root     75 Sep 17 22:08  .gitignore\n",
            "-rw------- 1 root root  28504 Nov 28 16:51  HGT_Transformer_Training_Colab.ipynb\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  hybrid\n",
            "-rw------- 1 root root   1095 Sep 17 22:03  LICENSE\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  Literature\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  outputs\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  pdfs\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  __pycache__\n",
            "-rw------- 1 root root  12437 Nov 27 08:46  README.md\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  scripts\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  src\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  toy\n",
            "-rw------- 1 root root  14204 Nov 28 16:53  verify_colab_setup.py\n",
            "drwx------ 2 root root   4096 Dec  1 08:19  Writings\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set up paths\n",
        "REPO_PATH = '/content/drive/MyDrive/benchmark'\n",
        "os.chdir(REPO_PATH)\n",
        "\n",
        "print(f\"Current directory: {os.getcwd()}\")\n",
        "print(f\"Repository contents:\")\n",
        "!ls -la"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "check-gpu"
      },
      "source": [
        "## 2. Verify GPU (A100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gpu-check",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9c5ae91-bef6-48cd-d9f7-24c0257eca76"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version: 2.5.1+cu124\n",
            "CUDA available: True\n",
            "CUDA version: 12.4\n",
            "GPU Device: NVIDIA A100-SXM4-80GB\n",
            "GPU Memory: 85.17 GB\n",
            "Number of GPUs: 1\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Check GPU availability\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"CUDA version: {torch.version.cuda}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU Device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB\")\n",
        "    print(f\"Number of GPUs: {torch.cuda.device_count()}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è WARNING: No GPU detected! Please enable GPU in Runtime > Change runtime type\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "install-deps"
      },
      "source": [
        "## 3. Install Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "install-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "67e79798-d860-43f0-c403-8b4561ee0788"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Installing stable PyTorch 2.5.1 and compatible PyG wheels...\n",
            "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
            "Collecting torch==2.5.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torch-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (908.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m908.2/908.2 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchvision==0.20.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchvision-0.20.1%2Bcu124-cp312-cp312-linux_x86_64.whl (7.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m7.3/7.3 MB\u001b[0m \u001b[31m146.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torchaudio==2.5.1+cu124\n",
            "  Downloading https://download.pytorch.org/whl/cu124/torchaudio-2.5.1%2Bcu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m81.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.20.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (4.15.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m99.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m64.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.4.5.8 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.2.1.3 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m12.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.5.147 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m41.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.21.5 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/cu124/nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m126.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting triton==3.1.0 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/triton-3.1.0-cp312-cp312-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (209.6 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m209.6/209.6 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch==2.5.1+cu124) (75.2.0)\n",
            "Collecting sympy==1.13.1 (from torch==2.5.1+cu124)\n",
            "  Downloading https://download.pytorch.org/whl/sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m142.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1+cu124) (2.0.2)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision==0.20.1+cu124) (11.3.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy==1.13.1->torch==2.5.1+cu124) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch==2.5.1+cu124) (3.0.3)\n",
            "Installing collected packages: triton, sympy, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torch, torchvision, torchaudio\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.5.0\n",
            "    Uninstalling triton-3.5.0:\n",
            "      Successfully uninstalled triton-3.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.14.0\n",
            "    Uninstalling sympy-1.14.0:\n",
            "      Successfully uninstalled sympy-1.14.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.6.77\n",
            "    Uninstalling nvidia-nvtx-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.6.85\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.6.85:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.6.85\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.27.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.27.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.27.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.7.77\n",
            "    Uninstalling nvidia-curand-cu12-10.3.7.77:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.7.77\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.3.0.4\n",
            "    Uninstalling nvidia-cufft-cu12-11.3.0.4:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.3.0.4\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.6.77\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.6.77:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.6.77\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.6.80\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.6.80:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.6.80\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.6.4.1\n",
            "    Uninstalling nvidia-cublas-cu12-12.6.4.1:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.6.4.1\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.4.2\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.4.2:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.4.2\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.10.2.21\n",
            "    Uninstalling nvidia-cudnn-cu12-9.10.2.21:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.10.2.21\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.7.1.2\n",
            "    Uninstalling nvidia-cusolver-cu12-11.7.1.2:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.7.1.2\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.9.0+cu126\n",
            "    Uninstalling torch-2.9.0+cu126:\n",
            "      Successfully uninstalled torch-2.9.0+cu126\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.24.0+cu126\n",
            "    Uninstalling torchvision-0.24.0+cu126:\n",
            "      Successfully uninstalled torchvision-0.24.0+cu126\n",
            "  Attempting uninstall: torchaudio\n",
            "    Found existing installation: torchaudio 2.9.0+cu126\n",
            "    Uninstalling torchaudio-2.9.0+cu126:\n",
            "      Successfully uninstalled torchaudio-2.9.0+cu126\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 sympy-1.13.1 torch-2.5.1+cu124 torchaudio-2.5.1+cu124 torchvision-0.20.1+cu124 triton-3.1.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch",
                  "torchgen"
                ]
              },
              "id": "011b20a866d8480686fed62f08327044"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in links: https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
            "Collecting torch-scatter\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_scatter-2.1.2%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (10.8 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m150.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-sparse\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_sparse-0.6.18%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (5.2 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m5.2/5.2 MB\u001b[0m \u001b[31m132.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-cluster\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_cluster-1.6.3%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m112.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting torch-spline-conv\n",
            "  Downloading https://data.pyg.org/whl/torch-2.5.0%2Bcu124/torch_spline_conv-1.2.2%2Bpt25cu124-cp312-cp312-linux_x86_64.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Installing collected packages: torch-spline-conv, torch-scatter, torch-sparse, torch-cluster\n",
            "Successfully installed torch-cluster-1.6.3+pt25cu124 torch-scatter-2.1.2+pt25cu124 torch-sparse-0.6.18+pt25cu124 torch-spline-conv-1.2.2+pt25cu124\n",
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (1.16.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (4.67.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.12/dist-packages (0.13.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (1.4.9)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
            "\n",
            "‚úÖ All dependencies installed! If you see version errors later, please restart the runtime (Runtime > Restart session). \n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Force install PyTorch 2.5.1 which has known compatible PyG wheels\n",
        "# This prevents the long \"Building wheels\" process\n",
        "print(\"üîÑ Installing stable PyTorch 2.5.1 and compatible PyG wheels...\")\n",
        "\n",
        "# Install PyTorch 2.5.1 + CUDA 12.4\n",
        "!pip install torch==2.5.1+cu124 torchvision==0.20.1+cu124 torchaudio==2.5.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "\n",
        "# Install PyG dependencies with matching wheels\n",
        "!pip install torch-scatter torch-sparse torch-cluster torch-spline-conv -f https://data.pyg.org/whl/torch-2.5.1+cu124.html\n",
        "!pip install torch-geometric\n",
        "\n",
        "# Install other dependencies\n",
        "!pip install numpy scipy tqdm matplotlib seaborn pandas\n",
        "\n",
        "print(\"\\n‚úÖ All dependencies installed! If you see version errors later, please restart the runtime (Runtime > Restart session). \")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "verify-data"
      },
      "source": [
        "## 4. Verify Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "verify-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2cbd4b54-8eae-4305-f702-63846e411168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Dataset found!\n",
            "Total graphs: 2000\n",
            "\n",
            "Sample graph info:\n",
            "  - Node features shape: (57984, 14)\n",
            "  - Edge index shape: (2, 63769)\n",
            "  - Node types shape: (57984,)\n",
            "  - Metadata: {'N_base': 604, 'T': 96, 'temporal_edges': ['soc', 'ramp', 'dr'], 'time_encoding': 'sinusoidal', 'target_horizon': 0, 'schema_version': '2.0-temporal'}\n",
            "\n",
            "üìä Node feature dimension: 14\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import numpy as np\n",
        "\n",
        "# Base repository path\n",
        "REPO_PATH = Path('/content/drive/MyDrive/benchmark')\n",
        "\n",
        "# Check dataset\n",
        "data_dir = REPO_PATH / 'outputs/graphs/hetero_temporal_v1'\n",
        "index_path = data_dir / 'dataset_index.json'\n",
        "\n",
        "if not index_path.exists():\n",
        "    print(f\"‚ùå ERROR: Dataset index not found at {index_path}\")\n",
        "    print(\"Please ensure your repository is correctly mounted from Google Drive.\")\n",
        "else:\n",
        "    # Load index\n",
        "    with open(index_path, 'r') as f:\n",
        "        index_data = json.load(f)\n",
        "\n",
        "    print(f\"‚úÖ Dataset found!\")\n",
        "    print(f\"Total graphs: {len(index_data['entries'])}\")\n",
        "\n",
        "    # Check first graph\n",
        "    # Handle Windows paths in JSON and join with REPO_PATH\n",
        "    first_graph_rel = index_data['entries'][0]['graph_file'].replace('\\\\', '/')\n",
        "    first_graph = REPO_PATH / first_graph_rel\n",
        "\n",
        "    if first_graph.exists():\n",
        "        sample = np.load(first_graph, allow_pickle=True)\n",
        "        print(f\"\\nSample graph info:\")\n",
        "        print(f\"  - Node features shape: {sample['node_features'].shape}\")\n",
        "        print(f\"  - Edge index shape: {sample['edge_index'].shape}\")\n",
        "        print(f\"  - Node types shape: {sample['node_types'].shape}\")\n",
        "        print(f\"  - Metadata: {sample['meta'].item()}\")\n",
        "\n",
        "        node_feature_dim = sample['node_features'].shape[1]\n",
        "        print(f\"\\nüìä Node feature dimension: {node_feature_dim}\")\n",
        "    else:\n",
        "        print(f\"‚ùå ERROR: First graph file not found at {first_graph}\")\n",
        "        print(f\"Attempted path: {first_graph}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "config"
      },
      "source": [
        "## 5. Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "config-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a5832d92-3541-4c6b-f40e-c81ef4affa1f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìã Training Configuration:\n",
            "  Model: HGT + Temporal Transformer\n",
            "  Batch size: 1\n",
            "  Attention heads: 4\n",
            "  Hidden dim: 64\n",
            "  Device: cuda\n"
          ]
        }
      ],
      "source": [
        "from dataclasses import dataclass\n",
        "\n",
        "@dataclass\n",
        "class TrainingConfig:\n",
        "    # Data\n",
        "    repo_path: str = '/content/drive/MyDrive/benchmark'\n",
        "    data_dir: str = '/content/drive/MyDrive/benchmark/outputs/graphs/hetero_temporal_v1'\n",
        "    train_split: float = 0.8\n",
        "\n",
        "    # Model - AUGMENT√â gr√¢ce √† √©conomie m√©moire\n",
        "    hidden_dim: int = 64          # ‚úÖ 4x plus que 32\n",
        "    num_spatial_layers: int = 1    # ‚úÖ Hi√©rarchie correcte\n",
        "    num_temporal_layers: int = 1   # ‚úÖ Capture temporalit√©\n",
        "    num_heads: int = 4             # ‚úÖ Attention riche\n",
        "    dropout: float = 0.15\n",
        "\n",
        "    # Training\n",
        "    loss_type: str = 'contrastive'\n",
        "    epochs: int = 150\n",
        "    batch_size: int = 1            # ‚úÖ Peut monter √† 3-4\n",
        "    lr: float = 3e-4\n",
        "    weight_decay: float = 1e-5\n",
        "    grad_clip: float = 1.0\n",
        "    warmup_epochs: int = 10\n",
        "\n",
        "    # Loss hyperparams\n",
        "    max_nodes: int = 256           # Subsample nodes\n",
        "    neg_sample_ratio: float = 0.1  # 20% de N*T comme n√©gatifs\n",
        "    temperature: float = 0.07\n",
        "\n",
        "    # Output\n",
        "    save_dir: str = '/content/drive/MyDrive/benchmark/outputs/encoders/hgt_transformer_optimized'\n",
        "    save_embeddings: bool = True\n",
        "    save_freq: int = 10\n",
        "\n",
        "    # Device\n",
        "    device: str = 'cuda'\n",
        "    num_workers: int = 0\n",
        "\n",
        "config = TrainingConfig()\n",
        "\n",
        "print(\"üìã Training Configuration:\")\n",
        "print(f\"  Model: HGT + Temporal Transformer\")\n",
        "print(f\"  Batch size: {config.batch_size}\")\n",
        "print(f\"  Attention heads: {config.num_heads}\")\n",
        "print(f\"  Hidden dim: {config.hidden_dim}\")\n",
        "print(f\"  Device: {config.device}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "setup-training"
      },
      "source": [
        "## 6. Setup Training Components"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "setup-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1dc8a1c-580f-4ba3-bb4f-447100c6abf9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading dataset...\n",
            "Found 2000 graphs\n",
            "Node feature dim: 14\n",
            "Train: 1600, Val: 400\n",
            "Train batches: 1600\n",
            "Val batches: 400\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "import json\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch_geometric.loader import DataLoader\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "# Add repo path to sys.path\n",
        "REPO_ROOT = Path('/content/drive/MyDrive/benchmark')\n",
        "sys.path.insert(0, str(REPO_ROOT))\n",
        "\n",
        "from src.gnn.models.temporal_hetero_gnn import HGTTemporalTransformer, TemporalGraphDataset\n",
        "\n",
        "# Load dataset\n",
        "print(\"Loading dataset...\")\n",
        "# Use config.data_dir if available, else hardcode\n",
        "data_dir = Path(config.data_dir)\n",
        "index_path = data_dir / \"dataset_index.json\"\n",
        "\n",
        "with open(index_path, 'r') as f:\n",
        "    index_data = json.load(f)\n",
        "\n",
        "# Fix path construction\n",
        "# Use REPO_ROOT defined above instead of config.repo_path to avoid AttributeError\n",
        "graph_files = []\n",
        "for e in index_data[\"entries\"]:\n",
        "    # Normalize path (replace backslash with forward slash) and join with repo_path\n",
        "    rel_path = e[\"graph_file\"].replace('\\\\', '/')\n",
        "    graph_files.append(REPO_ROOT / rel_path)\n",
        "\n",
        "print(f\"Found {len(graph_files)} graphs\")\n",
        "\n",
        "# Get node feature dim from first graph\n",
        "if not graph_files[0].exists():\n",
        "    raise FileNotFoundError(f\"Graph file not found: {graph_files[0]}\")\n",
        "\n",
        "sample_data = np.load(graph_files[0], allow_pickle=True)\n",
        "node_feature_dim = sample_data[\"node_features\"].shape[1]\n",
        "print(f\"Node feature dim: {node_feature_dim}\")\n",
        "\n",
        "# Create dataset (no target selection for encoder training)\n",
        "dataset = TemporalGraphDataset(graph_files, target_indices=None)\n",
        "\n",
        "# Split dataset\n",
        "train_size = int(config.train_split * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "print(f\"Train: {train_size}, Val: {val_size}\")\n",
        "\n",
        "# Create loaders\n",
        "train_loader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers=config.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "val_loader = DataLoader(\n",
        "    val_dataset,\n",
        "    batch_size=config.batch_size,\n",
        "    shuffle=False,\n",
        "    num_workers=config.num_workers,\n",
        "    pin_memory=True\n",
        ")\n",
        "\n",
        "print(f\"Train batches: {len(train_loader)}\")\n",
        "print(f\"Val batches: {len(val_loader)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "create-model"
      },
      "source": [
        "## 7. Create Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "model-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "197545e2-967a-4020-b108-c80c3cffb13a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Creating HGT + Temporal Transformer model...\n",
            "\n",
            "‚úÖ Model created!\n",
            "  Total parameters: 221,440\n",
            "  Trainable parameters: 221,440\n",
            "  Model size: ~0.89 MB (fp32)\n",
            "\n",
            "üìö Optimizer: AdamW (lr=0.0003, wd=1e-05)\n",
            "üìö Scheduler: Warmup (10 epochs) + Cosine Annealing\n"
          ]
        }
      ],
      "source": [
        "# Create model\n",
        "import gc\n",
        "\n",
        "# Delete old model if exists to free memory\n",
        "if 'model' in globals():\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "    print(\"üßπ Old model deleted and memory cleared.\")\n",
        "\n",
        "print(\"Creating HGT + Temporal Transformer model...\")\n",
        "model = HGTTemporalTransformer(\n",
        "    node_feature_dim=node_feature_dim,\n",
        "    hidden_dim=config.hidden_dim,\n",
        "    num_spatial_layers=config.num_spatial_layers,\n",
        "    num_temporal_layers=config.num_temporal_layers,\n",
        "    num_heads=config.num_heads,\n",
        "    dropout=config.dropout,\n",
        ")\n",
        "model = model.to(config.device)\n",
        "\n",
        "total_params = sum(p.numel() for p in model.parameters())\n",
        "trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "print(f\"\\n‚úÖ Model created!\")\n",
        "print(f\"  Total parameters: {total_params:,}\")\n",
        "print(f\"  Trainable parameters: {trainable_params:,}\")\n",
        "print(f\"  Model size: ~{total_params * 4 / 1e6:.2f} MB (fp32)\")\n",
        "\n",
        "# Optimizer with warmup\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.lr,\n",
        "    weight_decay=config.weight_decay\n",
        ")\n",
        "\n",
        "# Cosine annealing scheduler with warmup\n",
        "from torch.optim.lr_scheduler import CosineAnnealingLR, LinearLR, SequentialLR\n",
        "\n",
        "warmup_scheduler = LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=0.1,\n",
        "    end_factor=1.0,\n",
        "    total_iters=config.warmup_epochs\n",
        ")\n",
        "cosine_scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=config.epochs - config.warmup_epochs\n",
        ")\n",
        "scheduler = SequentialLR(\n",
        "    optimizer,\n",
        "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
        "    milestones=[config.warmup_epochs]\n",
        ")\n",
        "\n",
        "print(f\"\\nüìö Optimizer: AdamW (lr={config.lr}, wd={config.weight_decay})\")\n",
        "print(f\"üìö Scheduler: Warmup ({config.warmup_epochs} epochs) + Cosine Annealing\")"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5123148b",
        "outputId": "b94c090f-e7d9-4074-cf58-81b76c3d785d"
      },
      "source": [
        "import re\n",
        "import importlib\n",
        "import torch\n",
        "from src.gnn.models import temporal_hetero_gnn\n",
        "\n",
        "# Path to the model file\n",
        "file_path = '/content/drive/MyDrive/benchmark/src/gnn/models/temporal_hetero_gnn.py'\n",
        "\n",
        "print(f\"üîÑ Patching {file_path} for Mixed Precision support (Round 2)...\")\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    content = f.read()\n",
        "\n",
        "# Target line: h_new.index_add_(0, dst_idx, attn_out)\n",
        "# Fix: h_new.index_add_(0, dst_idx, attn_out.to(h_new.dtype))\n",
        "\n",
        "pattern = r\"(h_new\\.index_add_\\(0, dst_idx, attn_out\\))\"\n",
        "replacement = r\"h_new.index_add_(0, dst_idx, attn_out.to(h_new.dtype))\"\n",
        "\n",
        "new_content, count = re.subn(pattern, replacement, content)\n",
        "\n",
        "if count > 0:\n",
        "    # Backup\n",
        "    with open(file_path + \".bak2\", 'w') as f:\n",
        "        f.write(content)\n",
        "\n",
        "    # Write patched content\n",
        "    with open(file_path, 'w') as f:\n",
        "        f.write(new_content)\n",
        "\n",
        "    print(f\"‚úÖ Applied fix to {count} location(s).\")\n",
        "\n",
        "    # Reload the module\n",
        "    importlib.reload(temporal_hetero_gnn)\n",
        "    from src.gnn.models.temporal_hetero_gnn import HGTTemporalTransformer\n",
        "    print(\"‚úÖ Module reloaded successfully.\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Patch pattern not found. It might have been applied already.\")\n",
        "    # Debug context\n",
        "    if \"index_add_\" in content:\n",
        "        print(\"Found 'index_add_' usage:\")\n",
        "        for line in content.splitlines():\n",
        "            if \"index_add_\" in line:\n",
        "                print(line.strip())"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîÑ Patching /content/drive/MyDrive/benchmark/src/gnn/models/temporal_hetero_gnn.py for Mixed Precision support (Round 2)...\n",
            "‚ö†Ô∏è Patch pattern not found. It might have been applied already.\n",
            "Found 'index_add_' usage:\n",
            "h_new.index_add_(0, dst_idx, attn_out.to(h_new.dtype))\n",
            "h_new.index_add_(0, dst_idx, attn_out.to(h_new.dtype))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e4c05e91",
        "outputId": "1e9a3d91-3721-4eb9-db34-121a5e9488a2"
      },
      "source": [
        "# Re-create model again with the updated class\n",
        "import gc\n",
        "\n",
        "if 'model' in globals():\n",
        "    del model\n",
        "    gc.collect()\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "print(\"Re-initializing model with Round 2 patches...\")\n",
        "model = HGTTemporalTransformer(\n",
        "    node_feature_dim=node_feature_dim,\n",
        "    hidden_dim=config.hidden_dim,\n",
        "    num_spatial_layers=config.num_spatial_layers,\n",
        "    num_temporal_layers=config.num_temporal_layers,\n",
        "    num_heads=config.num_heads,\n",
        "    dropout=config.dropout,\n",
        ")\n",
        "model = model.to(config.device)\n",
        "\n",
        "# Re-initialize optimizer and scheduler\n",
        "optimizer = torch.optim.AdamW(\n",
        "    model.parameters(),\n",
        "    lr=config.lr,\n",
        "    weight_decay=config.weight_decay\n",
        ")\n",
        "\n",
        "warmup_scheduler = LinearLR(\n",
        "    optimizer,\n",
        "    start_factor=0.1,\n",
        "    end_factor=1.0,\n",
        "    total_iters=config.warmup_epochs\n",
        ")\n",
        "cosine_scheduler = CosineAnnealingLR(\n",
        "    optimizer,\n",
        "    T_max=config.epochs - config.warmup_epochs\n",
        ")\n",
        "scheduler = SequentialLR(\n",
        "    optimizer,\n",
        "    schedulers=[warmup_scheduler, cosine_scheduler],\n",
        "    milestones=[config.warmup_epochs]\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Model re-initialized. Please run the training cell again.\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Re-initializing model with Round 2 patches...\n",
            "‚úÖ Model re-initialized. Please run the training cell again.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "loss-functions"
      },
      "source": [
        "## 8. Loss Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "loss-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbf2ced0-bdc1-47af-92b0-88f6d32205ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Loss functions defined (3 versions optimis√©es)\n",
            "   - contrastive_loss_hybrid: Maximum √©conomie m√©moire (loop-based)\n",
            "   - contrastive_loss_hybrid_vectorized: Version vectoris√©e (plus rapide)\n",
            "   - contrastive_loss_optimized: RECOMMAND√âE (meilleur compromis)\n"
          ]
        }
      ],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch\n",
        "\n",
        "\n",
        "def contrastive_loss_hybrid(embeddings, temperature=0.07, max_nodes=512, max_negatives=2048):\n",
        "    \"\"\"\n",
        "    InfoNCE contrastive loss - HYBRIDE ULTRA-OPTIMIS√â\n",
        "\n",
        "    Combine deux strat√©gies d'√©conomie m√©moire:\n",
        "    1. Subsampling des nodes (comme votre version)\n",
        "    2. Sampling des n√©gatifs au lieu de matrice compl√®te\n",
        "\n",
        "    M√©moire: O(N*T*max_negatives) au lieu de O(N¬≤*T¬≤)\n",
        "\n",
        "    Args:\n",
        "        embeddings: [N, T, D] tensor\n",
        "        temperature: Softmax temperature\n",
        "        max_nodes: Maximum nodes pour subsample (si N > max_nodes)\n",
        "        max_negatives: Nombre de n√©gatifs √† sampler par anchor\n",
        "    \"\"\"\n",
        "    N, T, D = embeddings.shape\n",
        "    device = embeddings.device\n",
        "\n",
        "    # √âtape 1: Subsample nodes si n√©cessaire\n",
        "    node_indices_kept = None\n",
        "    if N > max_nodes:\n",
        "        perm = torch.randperm(N, device=device)\n",
        "        node_indices_kept = perm[:max_nodes]\n",
        "        embeddings = embeddings[node_indices_kept]  # [max_nodes, T, D]\n",
        "        N = max_nodes\n",
        "\n",
        "    # Flatten to [N*T, D]\n",
        "    flat = embeddings.view(N * T, D)\n",
        "    flat = F.normalize(flat, dim=1)\n",
        "\n",
        "    # √âtape 2: Pour chaque anchor, calculer seulement avec positifs + sample de n√©gatifs\n",
        "    total_loss = 0.0\n",
        "    num_valid_pairs = 0\n",
        "\n",
        "    # Cr√©er les paires positives (timesteps adjacents)\n",
        "    for i in range(N):\n",
        "        for t in range(T - 1):\n",
        "            anchor_idx = i * T + t\n",
        "            positive_idx = i * T + t + 1\n",
        "\n",
        "            # Similarit√© avec le positif\n",
        "            pos_sim = torch.dot(flat[anchor_idx], flat[positive_idx]) / temperature\n",
        "\n",
        "            # Sample des n√©gatifs (exclure anchor et positive)\n",
        "            all_indices = torch.arange(N * T, device=device)\n",
        "            mask = (all_indices != anchor_idx) & (all_indices != positive_idx)\n",
        "            neg_pool = all_indices[mask]\n",
        "\n",
        "            # Limiter le nombre de n√©gatifs\n",
        "            if neg_pool.size(0) > max_negatives:\n",
        "                neg_perm = torch.randperm(neg_pool.size(0), device=device)[:max_negatives]\n",
        "                neg_indices = neg_pool[neg_perm]\n",
        "            else:\n",
        "                neg_indices = neg_pool\n",
        "\n",
        "            # Similarit√©s avec n√©gatifs (batch matmul efficient)\n",
        "            neg_sims = torch.matmul(flat[neg_indices], flat[anchor_idx]) / temperature\n",
        "\n",
        "            # InfoNCE: log(exp(pos) / (exp(pos) + sum(exp(neg))))\n",
        "            all_sims = torch.cat([pos_sim.unsqueeze(0), neg_sims])\n",
        "            loss = -F.log_softmax(all_sims, dim=0)[0]\n",
        "\n",
        "            total_loss += loss\n",
        "            num_valid_pairs += 1\n",
        "\n",
        "    if num_valid_pairs == 0:\n",
        "        return torch.tensor(0.0, device=device, requires_grad=True)\n",
        "\n",
        "    return total_loss / num_valid_pairs\n",
        "\n",
        "\n",
        "def contrastive_loss_hybrid_vectorized(embeddings, temperature=0.07, max_nodes=512, max_negatives=2048):\n",
        "    \"\"\"\n",
        "    VERSION VECTORIS√âE (plus rapide) de la loss hybride\n",
        "\n",
        "    Traite tous les anchors d'un coup au lieu d'une boucle\n",
        "    \"\"\"\n",
        "    N, T, D = embeddings.shape\n",
        "    device = embeddings.device\n",
        "\n",
        "    # Subsample nodes si n√©cessaire\n",
        "    if N > max_nodes:\n",
        "        perm = torch.randperm(N, device=device)\n",
        "        embeddings = embeddings[perm[:max_nodes]]\n",
        "        N = max_nodes\n",
        "\n",
        "    # Flatten et normaliser\n",
        "    flat = embeddings.view(N * T, D)\n",
        "    flat = F.normalize(flat, dim=1)\n",
        "\n",
        "    # Cr√©er les indices des paires positives\n",
        "    node_ids = torch.arange(N, device=device).repeat_interleave(T - 1)\n",
        "    time_ids = torch.arange(T - 1, device=device).repeat(N)\n",
        "\n",
        "    anchor_indices = node_ids * T + time_ids           # [N*(T-1)]\n",
        "    positive_indices = node_ids * T + (time_ids + 1)   # [N*(T-1)]\n",
        "\n",
        "    num_pairs = anchor_indices.size(0)\n",
        "\n",
        "    # Embeddings des anchors et positifs\n",
        "    anchor_embs = flat[anchor_indices]      # [num_pairs, D]\n",
        "    positive_embs = flat[positive_indices]  # [num_pairs, D]\n",
        "\n",
        "    # Similarit√©s positives\n",
        "    pos_sims = (anchor_embs * positive_embs).sum(dim=1) / temperature  # [num_pairs]\n",
        "\n",
        "    # Sample n√©gatifs pour chaque anchor\n",
        "    # Strat√©gie: pour chaque anchor, sample al√©atoirement depuis tous les autres\n",
        "    total_nodes = N * T\n",
        "\n",
        "    # Cr√©er masque d'exclusion (anchor et son positive)\n",
        "    neg_sims_list = []\n",
        "\n",
        "    for i in range(num_pairs):\n",
        "        # Tous les indices sauf anchor et positive\n",
        "        exclude_mask = torch.ones(total_nodes, dtype=torch.bool, device=device)\n",
        "        exclude_mask[anchor_indices[i]] = False\n",
        "        exclude_mask[positive_indices[i]] = False\n",
        "\n",
        "        valid_negatives = torch.where(exclude_mask)[0]\n",
        "\n",
        "        # Sample\n",
        "        if valid_negatives.size(0) > max_negatives:\n",
        "            sampled = valid_negatives[torch.randperm(valid_negatives.size(0), device=device)[:max_negatives]]\n",
        "        else:\n",
        "            sampled = valid_negatives\n",
        "\n",
        "        # Similarit√©s\n",
        "        neg_sims = torch.matmul(flat[sampled], anchor_embs[i]) / temperature\n",
        "        neg_sims_list.append(neg_sims)\n",
        "\n",
        "    # Padding pour avoir m√™me taille (pour vectorisation)\n",
        "    max_len = max(ns.size(0) for ns in neg_sims_list)\n",
        "    neg_sims_padded = torch.full((num_pairs, max_len), float('-inf'), device=device)\n",
        "\n",
        "    for i, ns in enumerate(neg_sims_list):\n",
        "        neg_sims_padded[i, :ns.size(0)] = ns\n",
        "\n",
        "    # Combiner pos et neg\n",
        "    all_sims = torch.cat([pos_sims.unsqueeze(1), neg_sims_padded], dim=1)  # [num_pairs, 1+max_negatives]\n",
        "\n",
        "    # Log-softmax et prendre le premier (positif)\n",
        "    loss = -F.log_softmax(all_sims, dim=1)[:, 0].mean()\n",
        "\n",
        "    return loss\n",
        "\n",
        "\n",
        "# VERSION RECOMMAND√âE: Compromis vitesse/m√©moire\n",
        "def contrastive_loss_optimized(embeddings, temperature=0.07, max_nodes=512, neg_sample_ratio=0.2):\n",
        "    \"\"\"\n",
        "    VERSION OPTIMALE - Meilleur compromis vitesse/m√©moire\n",
        "\n",
        "    Au lieu de sampler max_negatives, sample un ratio de la population totale\n",
        "\n",
        "    Args:\n",
        "        embeddings: [N, T, D]\n",
        "        temperature: Temp√©rature softmax\n",
        "        max_nodes: Subsample nodes (si N > max_nodes)\n",
        "        neg_sample_ratio: Ratio de n√©gatifs √† sampler (0.2 = 20% de N*T)\n",
        "    \"\"\"\n",
        "    N, T, D = embeddings.shape\n",
        "    device = embeddings.device\n",
        "\n",
        "    # Subsample nodes si n√©cessaire\n",
        "    if N > max_nodes:\n",
        "        perm = torch.randperm(N, device=device)\n",
        "        embeddings = embeddings[perm[:max_nodes]]\n",
        "        N = max_nodes\n",
        "\n",
        "    # Flatten et normaliser\n",
        "    flat = embeddings.view(N * T, D)\n",
        "    flat = F.normalize(flat, dim=1)\n",
        "\n",
        "    total_nodes = N * T\n",
        "    max_negatives = max(100, int(total_nodes * neg_sample_ratio))  # Au moins 100 n√©gatifs\n",
        "\n",
        "    # Indices des paires positives\n",
        "    node_ids = torch.arange(N, device=device).repeat_interleave(T - 1)\n",
        "    time_ids = torch.arange(T - 1, device=device).repeat(N)\n",
        "    anchor_indices = node_ids * T + time_ids\n",
        "    positive_indices = node_ids * T + (time_ids + 1)\n",
        "\n",
        "    # Batch processing: traiter par chunks pour √©conomiser m√©moire\n",
        "    chunk_size = 256\n",
        "    num_pairs = anchor_indices.size(0)\n",
        "    total_loss = 0.0\n",
        "\n",
        "    for chunk_start in range(0, num_pairs, chunk_size):\n",
        "        chunk_end = min(chunk_start + chunk_size, num_pairs)\n",
        "        chunk_anchors = anchor_indices[chunk_start:chunk_end]\n",
        "        chunk_positives = positive_indices[chunk_start:chunk_end]\n",
        "\n",
        "        # Embeddings du chunk\n",
        "        anchor_embs = flat[chunk_anchors]\n",
        "        positive_embs = flat[chunk_positives]\n",
        "\n",
        "        # Similarit√©s positives\n",
        "        pos_sims = (anchor_embs * positive_embs).sum(dim=1, keepdim=True) / temperature\n",
        "\n",
        "        # Sample n√©gatifs communs pour tout le chunk (plus efficace)\n",
        "        all_neg_indices = torch.randperm(total_nodes, device=device)[:max_negatives]\n",
        "        neg_embs = flat[all_neg_indices]  # [max_negatives, D]\n",
        "\n",
        "        # Similarit√©s n√©gatives (batch matmul)\n",
        "        neg_sims = torch.matmul(anchor_embs, neg_embs.t()) / temperature  # [chunk_size, max_negatives]\n",
        "\n",
        "        # Combiner\n",
        "        all_sims = torch.cat([pos_sims, neg_sims], dim=1)  # [chunk_size, 1+max_negatives]\n",
        "\n",
        "        # Loss\n",
        "        chunk_loss = -F.log_softmax(all_sims, dim=1)[:, 0].mean()\n",
        "        total_loss += chunk_loss * (chunk_end - chunk_start)\n",
        "\n",
        "    return total_loss / num_pairs\n",
        "\n",
        "\n",
        "print(\"‚úÖ Loss functions defined (3 versions optimis√©es)\")\n",
        "print(\"   - contrastive_loss_hybrid: Maximum √©conomie m√©moire (loop-based)\")\n",
        "print(\"   - contrastive_loss_hybrid_vectorized: Version vectoris√©e (plus rapide)\")\n",
        "print(\"   - contrastive_loss_optimized: RECOMMAND√âE (meilleur compromis)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "training-loop"
      },
      "source": [
        "## 9. Training Loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "train-cell",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "761245fe-bc07-4781-c4eb-fd0b6d99cd80"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Training loop with node subsampling\n"
          ]
        }
      ],
      "source": [
        "from tqdm.notebook import tqdm\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.checkpoint import checkpoint\n",
        "\n",
        "\n",
        "def train_epoch_ultra_optimized(model, loader, optimizer, device, loss_type):\n",
        "    \"\"\"Training ultra-optimis√© avec subsampling des nodes.\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    num_batches = 0\n",
        "\n",
        "    accumulation_steps = 1  # ‚úÖ Pas d'accumulation avec batch_size=1\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Training\", leave=False)\n",
        "    for batch_idx, batch in enumerate(pbar):\n",
        "        batch = batch.to(device, non_blocking=True)\n",
        "\n",
        "        # Get N_base and T\n",
        "        if hasattr(batch, 'N_base'):\n",
        "            N_base = batch.N_base[0].item() if batch.N_base.dim() > 0 else batch.N_base.item()\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        if hasattr(batch, 'T'):\n",
        "            T = batch.T[0].item() if batch.T.dim() > 0 else batch.T.item()\n",
        "        else:\n",
        "            continue\n",
        "\n",
        "        # ‚úÖ SUBSAMPLE NODES pour √©conomiser m√©moire dans le forward\n",
        "        max_nodes_forward = 256  # Limiter √† 256 base nodes\n",
        "        if N_base > max_nodes_forward:\n",
        "            # Subsample les nodes ET leurs edges\n",
        "            node_indices = torch.randperm(N_base, device=device)[:max_nodes_forward]\n",
        "\n",
        "            # Cr√©er un mask pour les nodes √† garder (r√©p√©t√© pour chaque timestep)\n",
        "            keep_mask = torch.zeros(N_base * T, dtype=torch.bool, device=device)\n",
        "            for t in range(T):\n",
        "                keep_mask[node_indices + t * N_base] = True\n",
        "\n",
        "            # Filtrer nodes\n",
        "            batch.x = batch.x[keep_mask]\n",
        "            batch.node_type = batch.node_type[keep_mask]\n",
        "\n",
        "            # Filtrer edges (garder seulement ceux qui connectent les nodes gard√©s)\n",
        "            edge_mask = keep_mask[batch.edge_index[0]] & keep_mask[batch.edge_index[1]]\n",
        "            batch.edge_index = batch.edge_index[:, edge_mask]\n",
        "            batch.edge_type = batch.edge_type[edge_mask]\n",
        "\n",
        "            # Remap edge indices\n",
        "            old_to_new = torch.full((N_base * T,), -1, dtype=torch.long, device=device)\n",
        "            old_to_new[keep_mask] = torch.arange(keep_mask.sum(), device=device)\n",
        "            batch.edge_index = old_to_new[batch.edge_index]\n",
        "\n",
        "            N_base = max_nodes_forward\n",
        "\n",
        "        node_type = batch.node_type if hasattr(batch, 'node_type') else None\n",
        "\n",
        "        # Wrapper pour checkpointing\n",
        "        def model_forward(*inputs):\n",
        "            x, edge_index, edge_type, nt = inputs\n",
        "            return model(\n",
        "                x, edge_index, edge_type, nt,\n",
        "                N_base, T,\n",
        "                batch=None,  # Single graph\n",
        "                return_sequence=True,\n",
        "            )\n",
        "\n",
        "        # Forward avec autocast + checkpointing\n",
        "        with torch.amp.autocast(device_type='cuda', dtype=torch.bfloat16):\n",
        "            embeddings = checkpoint(\n",
        "                model_forward,\n",
        "                batch.x,\n",
        "                batch.edge_index,\n",
        "                batch.edge_type,\n",
        "                node_type,\n",
        "                use_reentrant=False\n",
        "            )\n",
        "\n",
        "        # Loss (float32 pour stabilit√©)\n",
        "        embeddings = embeddings.float()\n",
        "\n",
        "        loss = contrastive_loss_optimized(\n",
        "            embeddings,\n",
        "            temperature=0.07,\n",
        "            max_nodes=256,\n",
        "            neg_sample_ratio=0.1\n",
        "        )\n",
        "\n",
        "        # Backward\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=config.grad_clip)\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        num_batches += 1\n",
        "\n",
        "        pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
        "\n",
        "        # Cleanup p√©riodique\n",
        "        if batch_idx % 50 == 0:\n",
        "            torch.cuda.empty_cache()\n",
        "\n",
        "    return total_loss / max(num_batches, 1)\n",
        "\n",
        "\n",
        "print(\"‚úÖ Training loop with node subsampling\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "train-model"
      },
      "source": [
        "## 10. Train Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "training-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 544,
          "referenced_widgets": [
            "2ab9acd392c04d9faf47ce0ab394241f",
            "64b34534cefa4deb90a5abf919b217ed",
            "1d1b8930cd0d4e20b2311e9065cb220c",
            "2b48b9f55cc442d99479915749c95e63",
            "b434a192a8c842698a320281b4873022",
            "34b2b5cdd3a5444991ec33b9b742d463",
            "5358af7798d440949b7c1651bd2b8756",
            "ac43bcd0af554e339fe26017ffd0da82",
            "0e45d293efa34fd0ad33b3a2d52c229c",
            "2e0ac7c9037b4b80a318673bc8294ccb",
            "c9b201b9cf174112a3ac1daf43a6eeb8"
          ]
        },
        "outputId": "b212ac55-1ddd-4ed6-89c7-c3d57786a747"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üßπ Clearing GPU cache...\n",
            "\n",
            "üöÄ Starting training for 150 epochs...\n",
            "\n",
            "Loss type: contrastive\n",
            "Device: cuda\n",
            "Batch size: 1\n",
            "Precision: bfloat16 (AMP)\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Training:   0%|          | 0/1600 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2ab9acd392c04d9faf47ce0ab394241f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2707439097.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0;31m# Train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_epoch_ultra_optimized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;31m# Update scheduler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2043803812.py\u001b[0m in \u001b[0;36mtrain_epoch_ultra_optimized\u001b[0;34m(model, loader, optimizer, device, loss_type)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mpbar\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Training\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleave\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpbar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/notebook.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m             \u001b[0mit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__iter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m                 \u001b[0;31m# return super(tqdm...) will not catch exception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1181\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1182\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"__getitems__\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitems__\u001b[0;34m(self, indices)\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[attr-defined]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/drive/MyDrive/benchmark/src/gnn/models/temporal_hetero_gnn.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    652\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m         \u001b[0;31m# Load graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mdata_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_files\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_pickle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;31m# Extract components\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/numpy/lib/_npyio_impl.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding, max_header_size)\u001b[0m\n\u001b[1;32m    460\u001b[0m         \u001b[0m_ZIP_SUFFIX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mb'PK\\x05\\x06'\u001b[0m  \u001b[0;31m# empty zip files start with this\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m         \u001b[0mN\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMAGIC_PREFIX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 462\u001b[0;31m         \u001b[0mmagic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    463\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    464\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No data left in file\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import os\n",
        "\n",
        "# Optimization for memory fragmentation\n",
        "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
        "\n",
        "# Create save directory\n",
        "save_dir = Path(config.save_dir)\n",
        "save_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "import gc\n",
        "\n",
        "# Clear GPU memory before starting\n",
        "print(\"üßπ Clearing GPU cache...\")\n",
        "torch.cuda.empty_cache()\n",
        "gc.collect()\n",
        "\n",
        "# Training history\n",
        "history = {\n",
        "    'train_loss': [],\n",
        "    'lr': [],\n",
        "    'epoch_time': []\n",
        "}\n",
        "\n",
        "best_loss = float('inf')\n",
        "\n",
        "print(f\"\\nüöÄ Starting training for {config.epochs} epochs...\\n\")\n",
        "print(f\"Loss type: {config.loss_type}\")\n",
        "print(f\"Device: {config.device}\")\n",
        "print(f\"Batch size: {config.batch_size}\")\n",
        "print(f\"Precision: bfloat16 (AMP)\\n\")\n",
        "\n",
        "for epoch in range(1, config.epochs + 1):\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Train\n",
        "    train_loss = train_epoch_ultra_optimized(model, train_loader, optimizer, config.device, config.loss_type)\n",
        "\n",
        "    # Update scheduler\n",
        "    scheduler.step()\n",
        "\n",
        "    # Record history\n",
        "    epoch_time = time.time() - start_time\n",
        "    history['train_loss'].append(train_loss)\n",
        "    history['lr'].append(optimizer.param_groups[0]['lr'])\n",
        "    history['epoch_time'].append(epoch_time)\n",
        "\n",
        "    # Print progress\n",
        "    print(f\"Epoch {epoch:3d}/{config.epochs} | \"\n",
        "          f\"Loss: {train_loss:.6f} | \"\n",
        "          f\"LR: {optimizer.param_groups[0]['lr']:.6f} | \"\n",
        "          f\"Time: {epoch_time:.2f}s\")\n",
        "\n",
        "    # Save best model\n",
        "    if train_loss < best_loss:\n",
        "        best_loss = train_loss\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss': train_loss,\n",
        "            'config': config,\n",
        "        }, save_dir / \"best_encoder.pt\")\n",
        "        print(f\"  üíæ Saved best model (loss: {best_loss:.6f})\")\n",
        "\n",
        "    # Save checkpoint periodically\n",
        "    if epoch % config.save_freq == 0:\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'scheduler_state_dict': scheduler.state_dict(),\n",
        "            'loss': train_loss,\n",
        "            'history': history,\n",
        "            'config': config,\n",
        "        }, save_dir / f\"checkpoint_epoch_{epoch}.pt\")\n",
        "        print(f\"  üíæ Saved checkpoint at epoch {epoch}\")\n",
        "\n",
        "print(f\"\\n‚úÖ Training complete!\")\n",
        "print(f\"Best loss: {best_loss:.6f}\")\n",
        "print(f\"Model saved to: {save_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "visualize"
      },
      "source": [
        "## 11. Visualize Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "viz-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 344
        },
        "outputId": "fce2f36d-7e90-4019-f8f4-724ba123585f"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1800x400 with 3 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìä Training curves saved to: /content/drive/MyDrive/benchmark/outputs/encoders/hgt_transformer_optimized/training_curves.png\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "sns.set_style('whitegrid')\n",
        "fig, axes = plt.subplots(1, 3, figsize=(18, 4))\n",
        "\n",
        "# Training loss\n",
        "axes[0].plot(history['train_loss'], linewidth=2)\n",
        "axes[0].set_xlabel('Epoch', fontsize=12)\n",
        "axes[0].set_ylabel('Loss', fontsize=12)\n",
        "axes[0].set_title('Training Loss', fontsize=14, fontweight='bold')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate\n",
        "axes[1].plot(history['lr'], linewidth=2, color='orange')\n",
        "axes[1].set_xlabel('Epoch', fontsize=12)\n",
        "axes[1].set_ylabel('Learning Rate', fontsize=12)\n",
        "axes[1].set_title('Learning Rate Schedule', fontsize=14, fontweight='bold')\n",
        "axes[1].set_yscale('log')\n",
        "axes[1].grid(True, alpha=0.3)\n",
        "\n",
        "# Epoch time\n",
        "axes[2].plot(history['epoch_time'], linewidth=2, color='green')\n",
        "axes[2].set_xlabel('Epoch', fontsize=12)\n",
        "axes[2].set_ylabel('Time (seconds)', fontsize=12)\n",
        "axes[2].set_title('Training Time per Epoch', fontsize=14, fontweight='bold')\n",
        "axes[2].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig(save_dir / 'training_curves.png', dpi=150, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(f\"\\nüìä Training curves saved to: {save_dir / 'training_curves.png'}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "generate-embeddings"
      },
      "source": [
        "## 12. Generate Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "embeddings-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190,
          "referenced_widgets": [
            "c97589c024a64e6eb5bcf606039c0db5",
            "945e2bf9b6274703a8ee17d33666c342",
            "addeb9a6f77c46e28730a4ec630a2e49",
            "b4b252ea61e84b078981a4038c6d8416",
            "f1906592ec43412ebf23154030f1a8f1",
            "0a2d4584350d48baaed8268658d34e32",
            "5f0e69948bc54b32b40b51e7397b4a8a",
            "1515c941bd404f75abb2ec50516a1a28",
            "41dfeb8541e54c8a851901093a8ef4d3",
            "90d277b3a83a4e3e8174b550a806e214",
            "984b1cac1c004023a3409f6fe95b8baa"
          ]
        },
        "outputId": "855f19e7-51ce-47b2-90c0-4056678d63cd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üîÑ Generating embeddings for all graphs...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-1760511823.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  checkpoint = torch.load(save_dir / \"best_encoder.pt\")\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Generating embeddings:   0%|          | 0/2000 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c97589c024a64e6eb5bcf606039c0db5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "‚úÖ Saved 2000 embeddings to: /content/drive/MyDrive/benchmark/outputs/encoders/hgt_transformer_optimized/embeddings.npz\n",
            "   Total size: 17068.69 MB\n"
          ]
        }
      ],
      "source": [
        "if config.save_embeddings:\n",
        "    print(\"\\nüîÑ Generating embeddings for all graphs...\")\n",
        "\n",
        "    # Load best model\n",
        "    checkpoint = torch.load(save_dir / \"best_encoder.pt\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "\n",
        "    # Create loader for full dataset\n",
        "    full_loader = DataLoader(dataset, batch_size=1, shuffle=False, num_workers=2)\n",
        "\n",
        "    embeddings_list = []\n",
        "    metadata_list = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(full_loader, desc=\"Generating embeddings\"):\n",
        "            batch = batch.to(config.device)\n",
        "\n",
        "            # Get N_base and T\n",
        "            N_base = batch.N_base[0].item() if batch.N_base.dim() > 0 else batch.N_base.item()\n",
        "            T = batch.T[0].item() if batch.T.dim() > 0 else batch.T.item()\n",
        "            node_type = batch.node_type if hasattr(batch, 'node_type') else None\n",
        "\n",
        "            embeddings = model(\n",
        "                batch.x,\n",
        "                batch.edge_index,\n",
        "                batch.edge_type,\n",
        "                node_type,\n",
        "                N_base,\n",
        "                T,\n",
        "                batch=batch.batch if hasattr(batch, 'batch') else None,\n",
        "                return_sequence=True,\n",
        "            )\n",
        "\n",
        "            # Handle batched or single graph\n",
        "            if embeddings.dim() == 4:\n",
        "                for i in range(embeddings.size(0)):\n",
        "                    embeddings_list.append(embeddings[i].cpu().numpy())\n",
        "                    metadata_list.append({\"N_base\": N_base, \"T\": T, \"shape\": list(embeddings[i].shape)})\n",
        "            else:\n",
        "                embeddings_list.append(embeddings.cpu().numpy())\n",
        "                metadata_list.append({\"N_base\": N_base, \"T\": T, \"shape\": list(embeddings.shape)})\n",
        "\n",
        "    # Save embeddings\n",
        "    save_dict = {}\n",
        "    for i, (emb, meta) in enumerate(zip(embeddings_list, metadata_list)):\n",
        "        save_dict[f'embedding_{i:05d}'] = emb\n",
        "        save_dict[f'metadata_{i:05d}'] = np.array(meta, dtype=object)\n",
        "\n",
        "    save_dict['count'] = np.array(len(embeddings_list))\n",
        "\n",
        "    embeddings_path = save_dir / 'embeddings.npz'\n",
        "    np.savez_compressed(embeddings_path, **save_dict)\n",
        "\n",
        "    print(f\"\\n‚úÖ Saved {len(embeddings_list)} embeddings to: {embeddings_path}\")\n",
        "    print(f\"   Total size: {embeddings_path.stat().st_size / 1e6:.2f} MB\")\n",
        "else:\n",
        "    print(\"\\nSkipping embedding generation (config.save_embeddings=False)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "summary"
      },
      "source": [
        "## 13. Training Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "summary-cell",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 471
        },
        "outputId": "2fedc9b2-12a3-45ee-96e7-9c9b46f3917a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "================================================================================\n",
            "üéØ TRAINING SUMMARY\n",
            "================================================================================\n",
            "\n",
            "üìä Model Architecture:\n",
            "  - Type: HGT + Temporal Transformer (Encoder-only)\n",
            "  - Hidden dim: 64\n",
            "  - Spatial layers: 1\n",
            "  - Temporal layers: 1\n",
            "  - Attention heads: 4\n",
            "  - Total parameters: 221,440\n",
            "\n",
            "üìà Training Results:\n",
            "  - Best loss: inf\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4011706831.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"\\nüìà Training Results:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Best loss: {best_loss:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Final loss: {history['train_loss'][-1]:.6f}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Total epochs: {config.epochs}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"  - Avg time per epoch: {np.mean(history['epoch_time']):.2f}s\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üéØ TRAINING SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(f\"\\nüìä Model Architecture:\")\n",
        "print(f\"  - Type: HGT + Temporal Transformer (Encoder-only)\")\n",
        "print(f\"  - Hidden dim: {config.hidden_dim}\")\n",
        "print(f\"  - Spatial layers: {config.num_spatial_layers}\")\n",
        "print(f\"  - Temporal layers: {config.num_temporal_layers}\")\n",
        "print(f\"  - Attention heads: {config.num_heads}\")\n",
        "print(f\"  - Total parameters: {total_params:,}\")\n",
        "\n",
        "print(f\"\\nüìà Training Results:\")\n",
        "print(f\"  - Best loss: {best_loss:.6f}\")\n",
        "print(f\"  - Final loss: {history['train_loss'][-1]:.6f}\")\n",
        "print(f\"  - Total epochs: {config.epochs}\")\n",
        "print(f\"  - Avg time per epoch: {np.mean(history['epoch_time']):.2f}s\")\n",
        "print(f\"  - Total training time: {sum(history['epoch_time'])/3600:.2f} hours\")\n",
        "\n",
        "print(f\"\\nüíæ Saved Files:\")\n",
        "print(f\"  - Best model: {save_dir / 'best_encoder.pt'}\")\n",
        "if config.save_embeddings:\n",
        "    print(f\"  - Embeddings: {save_dir / 'embeddings.npz'}\")\n",
        "print(f\"  - Training curves: {save_dir / 'training_curves.png'}\")\n",
        "\n",
        "print(f\"\\nüöÄ Next Steps:\")\n",
        "print(f\"  1. Use embeddings for EBM training\")\n",
        "print(f\"  2. Analyze embedding quality (t-SNE, k-means)\")\n",
        "print(f\"  3. Fine-tune on downstream tasks if needed\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ TRAINING COMPLETED SUCCESSFULLY!\")\n",
        "print(\"=\"*80 + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SkgvgiS4efe0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2ab9acd392c04d9faf47ce0ab394241f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_64b34534cefa4deb90a5abf919b217ed",
              "IPY_MODEL_1d1b8930cd0d4e20b2311e9065cb220c",
              "IPY_MODEL_2b48b9f55cc442d99479915749c95e63"
            ],
            "layout": "IPY_MODEL_b434a192a8c842698a320281b4873022"
          }
        },
        "64b34534cefa4deb90a5abf919b217ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_34b2b5cdd3a5444991ec33b9b742d463",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5358af7798d440949b7c1651bd2b8756",
            "value": "Training:‚Äá‚Äá‚Äá0%"
          }
        },
        "1d1b8930cd0d4e20b2311e9065cb220c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "danger",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ac43bcd0af554e339fe26017ffd0da82",
            "max": 1600,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0e45d293efa34fd0ad33b3a2d52c229c",
            "value": 5
          }
        },
        "2b48b9f55cc442d99479915749c95e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2e0ac7c9037b4b80a318673bc8294ccb",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_c9b201b9cf174112a3ac1daf43a6eeb8",
            "value": "‚Äá5/1600‚Äá[00:10&lt;56:42,‚Äá‚Äá2.13s/it,‚Äáloss=6.9700]"
          }
        },
        "b434a192a8c842698a320281b4873022": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "34b2b5cdd3a5444991ec33b9b742d463": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5358af7798d440949b7c1651bd2b8756": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ac43bcd0af554e339fe26017ffd0da82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0e45d293efa34fd0ad33b3a2d52c229c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2e0ac7c9037b4b80a318673bc8294ccb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c9b201b9cf174112a3ac1daf43a6eeb8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c97589c024a64e6eb5bcf606039c0db5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_945e2bf9b6274703a8ee17d33666c342",
              "IPY_MODEL_addeb9a6f77c46e28730a4ec630a2e49",
              "IPY_MODEL_b4b252ea61e84b078981a4038c6d8416"
            ],
            "layout": "IPY_MODEL_f1906592ec43412ebf23154030f1a8f1"
          }
        },
        "945e2bf9b6274703a8ee17d33666c342": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0a2d4584350d48baaed8268658d34e32",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_5f0e69948bc54b32b40b51e7397b4a8a",
            "value": "Generating‚Äáembeddings:‚Äá100%"
          }
        },
        "addeb9a6f77c46e28730a4ec630a2e49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1515c941bd404f75abb2ec50516a1a28",
            "max": 2000,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_41dfeb8541e54c8a851901093a8ef4d3",
            "value": 2000
          }
        },
        "b4b252ea61e84b078981a4038c6d8416": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_90d277b3a83a4e3e8174b550a806e214",
            "placeholder": "‚Äã",
            "style": "IPY_MODEL_984b1cac1c004023a3409f6fe95b8baa",
            "value": "‚Äá2000/2000‚Äá[19:05&lt;00:00,‚Äá‚Äá2.19it/s]"
          }
        },
        "f1906592ec43412ebf23154030f1a8f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0a2d4584350d48baaed8268658d34e32": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5f0e69948bc54b32b40b51e7397b4a8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1515c941bd404f75abb2ec50516a1a28": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "41dfeb8541e54c8a851901093a8ef4d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "90d277b3a83a4e3e8174b550a806e214": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "984b1cac1c004023a3409f6fe95b8baa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}